{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# üöÄ **Setup Inicial - Preparando o Terreno para CrewAI**\n",
       "\n",
       "---\n",
       "\n",
       "## **üéØ O que vamos fazer neste m√≥dulo?**\n",
       "\n",
       "Antes de mergulharmos no mundo fascinante do CrewAI, precisamos preparar nosso ambiente de trabalho. √â como montar um escrit√≥rio - antes de contratar os funcion√°rios, voc√™ precisa ter as ferramentas, a infraestrutura e tudo funcionando perfeitamente.\n",
       "\n",
       "### **üìã Nossa Checklist de Setup:**\n",
       "1. **Instalar as depend√™ncias** - As ferramentas que vamos usar\n",
       "2. **Configurar os LLMs** - Os \"c√©rebros\" dos nossos agentes\n",
       "3. **Testar o ambiente** - Garantir que tudo est√° funcionando\n",
       "4. **Preparar para o pr√≥ximo m√≥dulo** - Deixar tudo pronto para come√ßar\n",
       "\n",
       "---\n",
       "\n",
       "## **üîç Por que precisamos de um setup espec√≠fico?**\n",
       "\n",
       "### **O Problema dos Ambientes de IA**\n",
       "Quando trabalhamos com IA, especialmente com m√∫ltiplas IAs trabalhando juntas (como no CrewAI), precisamos de um ambiente bem estruturado. √â como ter um escrit√≥rio onde cada funcion√°rio precisa de:\n",
       "- **Ferramentas espec√≠ficas** para seu trabalho\n",
       "- **Acesso √† internet** para buscar informa√ß√µes\n",
       "- **Comunica√ß√£o** com outros funcion√°rios\n",
       "- **Recursos computacionais** adequados\n",
       "\n",
       "### **Por que o Google Colab?**\n",
       "- **Gratuito** e acess√≠vel\n",
       "- **GPU dispon√≠vel** quando necess√°rio\n",
       "- **Ambiente isolado** e limpo\n",
       "- **F√°cil compartilhamento** de notebooks\n",
       "\n",
       "### **Por que o Hugging Face?**\n",
       "- **30.000 requisi√ß√µes gratuitas** por m√™s\n",
       "- **Modelos de qualidade** dispon√≠veis\n",
       "- **Sem necessidade** de cart√£o de cr√©dito\n",
       "- **Perfeito para aprendizado** e testes\n",
       "\n",
       "---\n",
       "\n",
       "## **üõ†Ô∏è Vamos come√ßar o Setup!**\n",
       "\n",
       "### **Passo 1: Instalando as Depend√™ncias**\n",
       "\n",
       "Primeiro, vamos instalar todas as bibliotecas que precisamos. √â como comprar as ferramentas para o escrit√≥rio antes dos funcion√°rios chegarem."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üõ†Ô∏è INSTALANDO AS DEPEND√äNCIAS\n",
       "# Esta c√©lula vai instalar todas as bibliotecas que precisamos\n",
       "\n",
       "!pip install crewai>=0.28.0\n",
       "!pip install langchain>=0.1.0\n",
       "!pip install langchain-community>=0.0.10\n",
       "!pip install langchain-core>=0.1.0\n",
       "!pip install huggingface_hub>=0.19.0\n",
       "!pip install python-dotenv>=1.0.0\n",
       "!pip install requests>=2.31.0\n",
       "!pip install pandas>=2.0.0\n",
       "!pip install numpy>=1.24.0\n",
       "\n",
       "print(\"‚úÖ Todas as depend√™ncias foram instaladas com sucesso!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Passo 2: Importando as Bibliotecas**\n",
       "\n",
       "Agora vamos importar todas as bibliotecas que acabamos de instalar. √â como abrir as caixas das ferramentas e deix√°-las prontas para uso."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üì¶ IMPORTANDO AS BIBLIOTECAS\n",
       "# Vamos importar tudo que precisamos para trabalhar com CrewAI\n",
       "\n",
       "# Bibliotecas principais do CrewAI\n",
       "from crewai import Agent, Task, Crew, Process\n",
       "from crewai.tools import BaseTool\n",
       "\n",
       "# Bibliotecas do LangChain (base do CrewAI)\n",
       "from langchain.llms import HuggingFaceHub\n",
       "from langchain_openai import ChatOpenAI\n",
       "from langchain.schema import HumanMessage, SystemMessage\n",
       "\n",
       "# Bibliotecas utilit√°rias\n",
       "import os\n",
       "from dotenv import load_dotenv\n",
       "import requests\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "\n",
       "# Carregando vari√°veis de ambiente\n",
       "load_dotenv()\n",
       "\n",
       "print(\"‚úÖ Todas as bibliotecas foram importadas com sucesso!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Passo 3: Configurando os LLMs (Os C√©rebros dos Nossos Agentes)**\n",
       "\n",
       "Agora vamos configurar os modelos de linguagem que v√£o ser os \"c√©rebros\" dos nossos agentes. √â como contratar funcion√°rios - voc√™ precisa definir qual tipo de especialista cada um vai ser.\n",
       "\n",
       "#### **üîç O que √© um LLM?**\n",
       "**LLM** = Large Language Model (Modelo de Linguagem Grande). √â o \"c√©rebro\" que permite aos agentes:\n",
       "- **Entender** o que voc√™ est√° pedindo\n",
       "- **Processar** informa√ß√µes complexas\n",
       "- **Gerar** respostas inteligentes\n",
       "- **Tomar decis√µes** baseadas em contexto\n",
       "\n",
       "#### **üéØ Nossa Estrat√©gia de LLMs:**\n",
       "1. **Primeira tentativa**: OpenAI (se voc√™ tiver API key)\n",
       "2. **Segunda tentativa**: Hugging Face (gratuito)\n",
       "3. **Fallback**: Modelo local (se necess√°rio)\n",
       "\n",
       "#### **üí° Por que m√∫ltiplas op√ß√µes?**\n",
       "√â como ter um plano A, B e C. Se um servi√ßo estiver indispon√≠vel ou caro, temos alternativas para continuar trabalhando."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üß† CONFIGURANDO OS LLMs\n",
       "# Vamos criar uma fun√ß√£o que tenta diferentes op√ß√µes de LLM\n",
       "\n",
       "def get_llm_colab():\n",
       "    \"\"\"\n",
       "    Retorna o melhor LLM dispon√≠vel no Colab\n",
       "    \n",
       "    Esta fun√ß√£o tenta diferentes op√ß√µes na seguinte ordem:\n",
       "    1. OpenAI (se voc√™ tiver API key)\n",
       "    2. Hugging Face (gratuito)\n",
       "    3. Modelo local (fallback)\n",
       "    \"\"\"\n",
       "    \n",
       "    print(\"üîç Procurando o melhor LLM dispon√≠vel...\")\n",
       "    \n",
       "    # Tentativa 1: OpenAI (melhor qualidade)\n",
       "    try:\n",
       "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
       "        if api_key:\n",
       "            print(\"‚úÖ Usando OpenAI GPT-3.5-turbo\")\n",
       "            return ChatOpenAI(\n",
       "                model=\"gpt-3.5-turbo\",\n",
       "                temperature=0.7,\n",
       "                api_key=api_key\n",
       "            )\n",
       "        else:\n",
       "            print(\"‚ö†Ô∏è OpenAI API key n√£o encontrada\")\n",
       "    except Exception as e:\n",
       "        print(f\"‚ùå Erro com OpenAI: {e}\")\n",
       "    \n",
       "    # Tentativa 2: Hugging Face (gratuito)\n",
       "    try:\n",
       "        token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
       "        if token:\n",
       "            print(\"‚úÖ Usando Hugging Face (gratuito)\")\n",
       "            return HuggingFaceHub(\n",
       "                repo_id=\"google/flan-t5-base\",\n",
       "                model_kwargs={\n",
       "                    \"temperature\": 0.7, \n",
       "                    \"max_length\": 512\n",
       "                },\n",
       "                huggingfacehub_api_token=token\n",
       "            )\n",
       "        else:\n",
       "            print(\"‚ö†Ô∏è Hugging Face token n√£o encontrado\")\n",
       "    except Exception as e:\n",
       "        print(f\"‚ùå Erro com Hugging Face: {e}\")\n",
       "    \n",
       "    # Fallback: Modelo local (se dispon√≠vel)\n",
       "    print(\"‚ö†Ô∏è Usando modelo local como fallback\")\n",
       "    return None\n",
       "\n",
       "# Configurando o LLM\n",
       "llm = get_llm_colab()\n",
       "\n",
       "if llm:\n",
       "    print(f\"üéâ LLM configurado com sucesso: {type(llm).__name__}\")\n",
       "else:\n",
       "    print(\"‚ö†Ô∏è Nenhum LLM configurado. Voc√™ precisar√° configurar uma API key.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Passo 4: Testando Nosso Setup**\n",
       "\n",
       "Agora vamos fazer um teste simples para garantir que tudo est√° funcionando. √â como fazer uma \"prova de fogo\" antes de come√ßar o trabalho real.\n",
       "\n",
       "#### **üß™ O que vamos testar:**\n",
       "1. **Conex√£o com o LLM** - Se conseguimos gerar respostas\n",
       "2. **Importa√ß√µes do CrewAI** - Se todas as classes est√£o dispon√≠veis\n",
       "3. **Ambiente geral** - Se tudo est√° funcionando como esperado\n",
       "\n",
       "#### **üéØ Por que testar agora?**\n",
       "√â melhor descobrir problemas agora do que no meio de um projeto complexo. √â como testar as ferramentas antes de come√ßar a construir uma casa."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üß™ TESTANDO O SETUP\n",
       "# Vamos fazer alguns testes para garantir que tudo est√° funcionando\n",
       "\n",
       "print(\"üß™ Iniciando testes do setup...\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "# Teste 1: Verificando se o LLM est√° funcionando\n",
       "if llm:\n",
       "    try:\n",
       "        print(\"üîç Teste 1: Testando o LLM...\")\n",
       "        \n",
       "        # Teste simples com o LLM\n",
       "        if hasattr(llm, 'invoke'):\n",
       "            response = llm.invoke(\"Diga 'Ol√°, mundo!' em uma frase simples.\")\n",
       "            print(f\"‚úÖ LLM respondeu: {response}\")\n",
       "        else:\n",
       "            response = llm(\"Diga 'Ol√°, mundo!' em uma frase simples.\")\n",
       "            print(f\"‚úÖ LLM respondeu: {response}\")\n",
       "            \n",
       "    except Exception as e:\n",
       "        print(f\"‚ùå Erro no teste do LLM: {e}\")\n",
       "else:\n",
       "    print(\"‚ö†Ô∏è LLM n√£o configurado - pulando teste\")\n",
       "\n",
       "# Teste 2: Verificando as classes do CrewAI\n",
       "try:\n",
       "    print(\"\\nüîç Teste 2: Verificando classes do CrewAI...\")\n",
       "    \n",
       "    # Testando se conseguimos criar objetos b√°sicos\n",
       "    test_agent = Agent(\n",
       "        role=\"Teste\",\n",
       "        goal=\"Testar o setup\",\n",
       "        backstory=\"Sou um agente de teste\",\n",
       "        verbose=True\n",
       "    )\n",
       "    \n",
       "    test_task = Task(\n",
       "        description=\"Teste simples\",\n",
       "        agent=test_agent\n",
       "    )\n",
       "    \n",
       "    print(\"‚úÖ Classes do CrewAI funcionando perfeitamente!\")\n",
       "    \n",
       "except Exception as e:\n",
       "    print(f\"‚ùå Erro nas classes do CrewAI: {e}\")\n",
       "\n",
       "# Teste 3: Verificando bibliotecas utilit√°rias\n",
       "try:\n",
       "    print(\"\\nüîç Teste 3: Verificando bibliotecas utilit√°rias...\")\n",
       "    \n",
       "    # Teste com pandas\n",
       "    df = pd.DataFrame({'teste': [1, 2, 3]})\n",
       "    print(f\"‚úÖ Pandas funcionando: {df.shape[0]} linhas criadas\")\n",
       "    \n",
       "    # Teste com numpy\n",
       "    arr = np.array([1, 2, 3])\n",
       "    print(f\"‚úÖ Numpy funcionando: array com {len(arr)} elementos\")\n",
       "    \n",
       "except Exception as e:\n",
       "    print(f\"‚ùå Erro nas bibliotecas utilit√°rias: {e}\")\n",
       "\n",
       "print(\"\\n\" + \"=\" * 50)\n",
       "print(\"üéâ Testes do setup conclu√≠dos!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Passo 5: Configurando Vari√°veis de Ambiente (Opcional)**\n",
       "\n",
       "Se voc√™ quiser usar APIs pagas (como OpenAI), voc√™ pode configurar suas chaves de API aqui. √â como dar as chaves do escrit√≥rio para os funcion√°rios que precisam de acesso especial.\n",
       "\n",
       "#### **üîë Como obter as chaves de API:**\n",
       "\n",
       "**Para OpenAI:**\n",
       "1. Acesse [platform.openai.com](https://platform.openai.com)\n",
       "2. Crie uma conta ou fa√ßa login\n",
       "3. V√° em \"API Keys\"\n",
       "4. Crie uma nova chave\n",
       "5. Copie a chave (ela come√ßa com `sk-`)\n",
       "\n",
       "**Para Hugging Face:**\n",
       "1. Acesse [huggingface.co](https://huggingface.co)\n",
       "2. Crie uma conta ou fa√ßa login\n",
       "3. V√° em \"Settings\" > \"Access Tokens\"\n",
       "4. Crie um novo token\n",
       "5. Copie o token\n",
       "\n",
       "#### **‚ö†Ô∏è Importante:**\n",
       "- **Nunca compartilhe** suas chaves de API\n",
       "- **Use vari√°veis de ambiente** para seguran√ßa\n",
       "- **O curso funciona 100%** com op√ß√µes gratuitas"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üîë CONFIGURANDO VARI√ÅVEIS DE AMBIENTE (OPCIONAL)\n",
       "# Descomente e configure se voc√™ tiver chaves de API\n",
       "\n",
       "# Para OpenAI (opcional)\n",
       "# os.environ[\"OPENAI_API_KEY\"] = \"sua-chave-aqui\"\n",
       "\n",
       "# Para Hugging Face (recomendado - gratuito)\n",
       "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"seu-token-aqui\"\n",
       "\n",
       "print(\"üîë Para configurar APIs, descomente as linhas acima e adicione suas chaves\")\n",
       "print(\"üí° O curso funciona perfeitamente com op√ß√µes gratuitas!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **üéØ Resumo do que fizemos**\n",
       "\n",
       "### **‚úÖ Setup Completo Realizado:**\n",
       "1. **Instalamos** todas as depend√™ncias necess√°rias\n",
       "2. **Importamos** as bibliotecas principais\n",
       "3. **Configuramos** os LLMs com m√∫ltiplas op√ß√µes\n",
       "4. **Testamos** todo o ambiente\n",
       "5. **Preparamos** para configura√ß√£o de APIs (opcional)\n",
       "\n",
       "### **üîç Conceitos que aprendemos:**\n",
       "- **LLM (Large Language Model)**: O \"c√©rebro\" dos nossos agentes\n",
       "- **Vari√°veis de ambiente**: Forma segura de configurar APIs\n",
       "- **Estrat√©gia de fallback**: Ter planos B e C quando o plano A falha\n",
       "- **Setup robusto**: Preparar o ambiente antes de come√ßar\n",
       "\n",
       "### **üéØ O que vem no pr√≥ximo m√≥dulo:**\n",
       "No pr√≥ximo m√≥dulo, vamos mergulhar no **CrewAI** de verdade! Vamos aprender:\n",
       "- **O que √© CrewAI** e por que √© revolucion√°rio\n",
       "- **Como funciona** a colabora√ß√£o entre IAs\n",
       "- **Criar nosso primeiro** sistema de agentes\n",
       "- **Entender** a diferen√ßa entre agentes individuais e equipes\n",
       "\n",
       "---\n",
       "\n",
       "## **üí° Dica do Professor**\n",
       "\n",
       "> **\"Um setup bem feito √© metade do trabalho!\"** - √â como montar um escrit√≥rio: se voc√™ preparar tudo direito no come√ßo, o trabalho flui muito melhor depois.\n",
       "\n",
       "### **üöÄ Pr√≥ximo Passo:**\n",
       "Agora que temos tudo funcionando, vamos para o **M√≥dulo 1: Introdu√ß√£o ao CrewAI**!\n",
       "\n",
       "**üéØ Prepare-se para descobrir como criar um ex√©rcito de IAs que trabalha em equipe!**"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }