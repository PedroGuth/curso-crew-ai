{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# ðŸš€ **Setup Inicial - Preparando o Terreno para CrewAI**\n",
       "\n",
       "---\n",
       "\n",
       "## **ðŸŽ¯ O que vamos fazer neste mÃ³dulo?**\n",
       "\n",
       "Antes de mergulharmos no mundo fascinante do CrewAI, precisamos preparar nosso ambiente de trabalho. Ã‰ como montar um escritÃ³rio - antes de contratar os funcionÃ¡rios, vocÃª precisa ter as ferramentas, a infraestrutura e tudo funcionando perfeitamente.\n",
       "\n",
       "### **ðŸ“‹ Nossa Checklist de Setup:**\n",
       "1. **Instalar as dependÃªncias** - As ferramentas que vamos usar\n",
       "2. **Configurar os LLMs** - Os \"cÃ©rebros\" dos nossos agentes\n",
       "3. **Testar o ambiente** - Garantir que tudo estÃ¡ funcionando\n",
       "4. **Preparar para o prÃ³ximo mÃ³dulo** - Deixar tudo pronto para comeÃ§ar\n",
       "\n",
       "---\n",
       "\n",
       "## **ðŸ” Por que precisamos de um setup especÃ­fico?**\n",
       "\n",
       "### **O Problema dos Ambientes de IA**\n",
       "Quando trabalhamos com IA, especialmente com mÃºltiplas IAs trabalhando juntas (como no CrewAI), precisamos de um ambiente bem estruturado. Ã‰ como ter um escritÃ³rio onde cada funcionÃ¡rio precisa de:\n",
       "- **Ferramentas especÃ­ficas** para seu trabalho\n",
       "- **Acesso Ã  internet** para buscar informaÃ§Ãµes\n",
       "- **ComunicaÃ§Ã£o** com outros funcionÃ¡rios\n",
       "- **Recursos computacionais** adequados\n",
       "\n",
       "### **Por que o Google Colab?**\n",
       "- **Gratuito** e acessÃ­vel\n",
       "- **GPU disponÃ­vel** quando necessÃ¡rio\n",
       "- **Ambiente isolado** e limpo\n",
       "- **FÃ¡cil compartilhamento** de notebooks\n",
       "\n",
       "### **Por que o Hugging Face?**\n",
       "- **30.000 requisiÃ§Ãµes gratuitas** por mÃªs\n",
       "- **Modelos de qualidade** disponÃ­veis\n",
       "- **Sem necessidade** de cartÃ£o de crÃ©dito\n",
       "- **Perfeito para aprendizado** e testes\n",
       "\n",
       "---\n",
       "\n",
       "## **ðŸ› ï¸ Vamos comeÃ§ar o Setup!**\n",
       "\n",
       "### **Passo 1: Instalando as DependÃªncias**\n",
       "\n",
       "Primeiro, vamos instalar todas as bibliotecas que precisamos. Ã‰ como comprar as ferramentas para o escritÃ³rio antes dos funcionÃ¡rios chegarem."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ðŸ› ï¸ INSTALANDO AS DEPENDÃŠNCIAS\n",
       "# Esta cÃ©lula vai instalar todas as bibliotecas que precisamos\n",
       "\n",
       "!pip install crewai>=0.28.0\n",
       "!pip install langchain>=0.1.0\n",
       "!pip install langchain-community>=0.0.10\n",
       "!pip install langchain-core>=0.1.0\n",
       "!pip install huggingface_hub>=0.19.0\n",
       "!pip install python-dotenv>=1.0.0\n",
       "!pip install requests>=2.31.0\n",
       "!pip install pandas>=2.0.0\n",
       "!pip install numpy>=1.24.0\n",
       "\n",
       "print(\"âœ… Todas as dependÃªncias foram instaladas com sucesso!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Passo 2: Importando as Bibliotecas**\n",
       "\n",
       "Agora vamos importar todas as bibliotecas que acabamos de instalar. Ã‰ como abrir as caixas das ferramentas e deixÃ¡-las prontas para uso."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ðŸ“¦ IMPORTANDO AS BIBLIOTECAS\n",
       "# Vamos importar tudo que precisamos para trabalhar com CrewAI\n",
       "\n",
       "# Bibliotecas principais do CrewAI\n",
       "from crewai import Agent, Task, Crew, Process\n",
       "from crewai.tools import BaseTool\n",
       "\n",
       "# Bibliotecas do LangChain (base do CrewAI)\n",
       "from langchain.llms import HuggingFaceHub\n",
       "from langchain_openai import ChatOpenAI\n",
       "from langchain.schema import HumanMessage, SystemMessage\n",
       "\n",
       "# Bibliotecas utilitÃ¡rias\n",
       "import os\n",
       "from dotenv import load_dotenv\n",
       "import requests\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "\n",
       "# Carregando variÃ¡veis de ambiente\n",
       "load_dotenv()\n",
       "\n",
       "print(\"âœ… Todas as bibliotecas foram importadas com sucesso!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Passo 3: Configurando os LLMs (Os CÃ©rebros dos Nossos Agentes)**\n",
       "\n",
       "Agora vamos configurar os modelos de linguagem que vÃ£o ser os \"cÃ©rebros\" dos nossos agentes. Ã‰ como contratar funcionÃ¡rios - vocÃª precisa definir qual tipo de especialista cada um vai ser.\n",
       "\n",
       "#### **ðŸ” O que Ã© um LLM?**\n",
       "**LLM** = Large Language Model (Modelo de Linguagem Grande). Ã‰ o \"cÃ©rebro\" que permite aos agentes:\n",
       "- **Entender** o que vocÃª estÃ¡ pedindo\n",
       "- **Processar** informaÃ§Ãµes complexas\n",
       "- **Gerar** respostas inteligentes\n",
       "- **Tomar decisÃµes** baseadas em contexto\n",
       "\n",
       "#### **ðŸŽ¯ Nossa EstratÃ©gia de LLMs:**\n",
       "1. **Primeira tentativa**: OpenAI (se vocÃª tiver API key)\n",
       "2. **Segunda tentativa**: Hugging Face (gratuito)\n",
       "3. **Fallback**: Modelo local (se necessÃ¡rio)\n",
       "\n",
       "#### **ðŸ’¡ Por que mÃºltiplas opÃ§Ãµes?**\n",
       "Ã‰ como ter um plano A, B e C. Se um serviÃ§o estiver indisponÃ­vel ou caro, temos alternativas para continuar trabalhando."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ðŸ§  CONFIGURANDO OS LLMs\n",
       "# Vamos criar uma funÃ§Ã£o que tenta diferentes opÃ§Ãµes de LLM\n",
       "\n",
       "def get_llm_colab():\n",
       "    \"\"\"\n",
       "    Retorna o melhor LLM disponÃ­vel no Colab\n",
       "    \n",
       "    Esta funÃ§Ã£o tenta diferentes opÃ§Ãµes na seguinte ordem:\n",
       "    1. OpenAI (se vocÃª tiver API key)\n",
       "    2. Hugging Face (gratuito)\n",
       "    3. Modelo local (fallback)\n",
       "    \"\"\"\n",
       "    \n",
       "    print(\"ðŸ” Procurando o melhor LLM disponÃ­vel...\")\n",
       "    \n",
       "    # Tentativa 1: OpenAI (melhor qualidade)\n",
       "    try:\n",
       "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
       "        if api_key:\n",
       "            print(\"âœ… Usando OpenAI GPT-3.5-turbo\")\n",
       "            return ChatOpenAI(\n",
       "                model=\"gpt-3.5-turbo\",\n",
       "                temperature=0.7,\n",
       "                api_key=api_key\n",
       "            )\n",
       "        else:\n",
       "            print(\"âš ï¸ OpenAI API key nÃ£o encontrada\")\n",
       "    except Exception as e:\n",
       "        print(f\"âŒ Erro com OpenAI: {e}\")\n",
       "    \n",
       "    # Tentativa 2: Hugging Face (gratuito)\n",
       "    try:\n",
       "        token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
       "        if token:\n",
       "            print(\"âœ… Usando Hugging Face (gratuito)\")\n",
       "            return HuggingFaceHub(\n",
       "                repo_id=\"google/flan-t5-base\",\n",
       "                model_kwargs={\n",
       "                    \"temperature\": 0.7, \n",
       "                    \"max_length\": 512\n",
       "                },\n",
       "                huggingfacehub_api_token=token\n",
       "            )\n",
       "        else:\n",
       "            print(\"âš ï¸ Hugging Face token nÃ£o encontrado\")\n",
       "    except Exception as e:\n",
       "        print(f\"âŒ Erro com Hugging Face: {e}\")\n",
       "    \n",
       "    # Fallback: Modelo local (se disponÃ­vel)\n",
       "    print(\"âš ï¸ Usando modelo local como fallback\")\n",
       "    return None\n",
       "\n",
       "# Configurando o LLM\n",
       "llm = get_llm_colab()\n",
       "\n",
       "if llm:\n",
       "    print(f\"ðŸŽ‰ LLM configurado com sucesso: {type(llm).__name__}\")\n",
       "else:\n",
       "    print(\"âš ï¸ Nenhum LLM configurado. VocÃª precisarÃ¡ configurar uma API key.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Passo 4: Testando Nosso Setup**\n",
       "\n",
       "Agora vamos fazer um teste simples para garantir que tudo estÃ¡ funcionando. Ã‰ como fazer uma \"prova de fogo\" antes de comeÃ§ar o trabalho real.\n",
       "\n",
       "#### **ðŸ§ª O que vamos testar:**\n",
       "1. **ConexÃ£o com o LLM** - Se conseguimos gerar respostas\n",
       "2. **ImportaÃ§Ãµes do CrewAI** - Se todas as classes estÃ£o disponÃ­veis\n",
       "3. **Ambiente geral** - Se tudo estÃ¡ funcionando como esperado\n",
       "\n",
       "#### **ðŸŽ¯ Por que testar agora?**\n",
       "Ã‰ melhor descobrir problemas agora do que no meio de um projeto complexo. Ã‰ como testar as ferramentas antes de comeÃ§ar a construir uma casa."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ðŸ§ª TESTANDO O SETUP\n",
       "# Vamos fazer alguns testes para garantir que tudo estÃ¡ funcionando\n",
       "\n",
       "print(\"ðŸ§ª Iniciando testes do setup...\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "# Teste 1: Verificando se o LLM estÃ¡ funcionando\n",
       "if llm:\n",
       "    try:\n",
       "        print(\"ðŸ” Teste 1: Testando o LLM...\")\n",
       "        \n",
       "        # Teste simples com o LLM\n",
       "        if hasattr(llm, 'invoke'):\n",
       "            response = llm.invoke(\"Diga 'OlÃ¡, mundo!' em uma frase simples.\")\n",
       "            print(f\"âœ… LLM respondeu: {response}\")\n",
       "        else:\n",
       "            response = llm(\"Diga 'OlÃ¡, mundo!' em uma frase simples.\")\n",
       "            print(f\"âœ… LLM respondeu: {response}\")\n",
       "            \n",
       "    except Exception as e:\n",
       "        print(f\"âŒ Erro no teste do LLM: {e}\")\n",
       "else:\n",
       "    print(\"âš ï¸ LLM nÃ£o configurado - pulando teste\")\n",
       "\n",
       "# Teste 2: Verificando as classes do CrewAI\n",
       "try:\n",
       "    print(\"\\nðŸ” Teste 2: Verificando classes do CrewAI...\")\n",
       "    \n",
       "    # Testando se conseguimos criar objetos bÃ¡sicos\n",
       "    test_agent = Agent(\n",
       "        role=\"Teste\",\n",
       "        goal=\"Testar o setup\",\n",
       "        backstory=\"Sou um agente de teste\",\n",
       "        verbose=True\n",
       "    )\n",
       "    \n",
       "    test_task = Task(\n",
       "        description=\"Teste simples\",\n",
       "        agent=test_agent\n",
       "    )\n",
       "    \n",
       "    print(\"âœ… Classes do CrewAI funcionando perfeitamente!\")\n",
       "    \n",
       "except Exception as e:\n",
       "    print(f\"âŒ Erro nas classes do CrewAI: {e}\")\n",
       "\n",
       "# Teste 3: Verificando bibliotecas utilitÃ¡rias\n",
       "try:\n",
       "    print(\"\\nðŸ” Teste 3: Verificando bibliotecas utilitÃ¡rias...\")\n",
       "    \n",
       "    # Teste com pandas\n",
       "    df = pd.DataFrame({'teste': [1, 2, 3]})\n",
       "    print(f\"âœ… Pandas funcionando: {df.shape[0]} linhas criadas\")\n",
       "    \n",
       "    # Teste com numpy\n",
       "    arr = np.array([1, 2, 3])\n",
       "    print(f\"âœ… Numpy funcionando: array com {len(arr)} elementos\")\n",
       "    \n",
       "except Exception as e:\n",
       "    print(f\"âŒ Erro nas bibliotecas utilitÃ¡rias: {e}\")\n",
       "\n",
       "print(\"\\n\" + \"=\" * 50)\n",
       "print(\"ðŸŽ‰ Testes do setup concluÃ­dos!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Passo 5: Configurando VariÃ¡veis de Ambiente (Opcional)**\n",
       "\n",
       "Se vocÃª quiser usar APIs pagas (como OpenAI), vocÃª pode configurar suas chaves de API aqui. Ã‰ como dar as chaves do escritÃ³rio para os funcionÃ¡rios que precisam de acesso especial.\n",
       "\n",
       "#### **ðŸ”‘ Como obter as chaves de API:**\n",
       "\n",
       "**Para OpenAI:**\n",
       "1. Acesse [platform.openai.com](https://platform.openai.com)\n",
       "2. Crie uma conta ou faÃ§a login\n",
       "3. VÃ¡ em \"API Keys\"\n",
       "4. Crie uma nova chave\n",
       "5. Copie a chave (ela comeÃ§a com `sk-`)\n",
       "\n",
       "**Para Hugging Face:**\n",
       "1. Acesse [huggingface.co](https://huggingface.co)\n",
       "2. Crie uma conta ou faÃ§a login\n",
       "3. VÃ¡ em \"Settings\" > \"Access Tokens\"\n",
       "4. Crie um novo token\n",
       "5. Copie o token\n",
       "\n",
       "#### **âš ï¸ Importante:**\n",
       "- **Nunca compartilhe** suas chaves de API\n",
       "- **Use variÃ¡veis de ambiente** para seguranÃ§a\n",
       "- **O curso funciona 100%** com opÃ§Ãµes gratuitas"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ðŸ”‘ CONFIGURANDO VARIÃVEIS DE AMBIENTE (OPCIONAL)\n",
       "# Descomente e configure se vocÃª tiver chaves de API\n",
       "\n",
       "# Para OpenAI (opcional)\n",
       "# os.environ[\"OPENAI_API_KEY\"] = \"sua-chave-aqui\"\n",
       "\n",
       "# Para Hugging Face (recomendado - gratuito)\n",
       "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"seu-token-aqui\"\n",
       "\n",
       "print(\"ðŸ”‘ Para configurar APIs, descomente as linhas acima e adicione suas chaves\")\n",
       "print(\"ðŸ’¡ O curso funciona perfeitamente com opÃ§Ãµes gratuitas!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **ðŸŽ¯ Resumo do que fizemos**\n",
       "\n",
       "### **âœ… Setup Completo Realizado:**\n",
       "1. **Instalamos** todas as dependÃªncias necessÃ¡rias\n",
       "2. **Importamos** as bibliotecas principais\n",
       "3. **Configuramos** os LLMs com mÃºltiplas opÃ§Ãµes\n",
       "4. **Testamos** todo o ambiente\n",
       "5. **Preparamos** para configuraÃ§Ã£o de APIs (opcional)\n",
       "\n",
       "### **ðŸ” Conceitos que aprendemos:**\n",
       "- **LLM (Large Language Model)**: O \"cÃ©rebro\" dos nossos agentes\n",
       "- **VariÃ¡veis de ambiente**: Forma segura de configurar APIs\n",
       "- **EstratÃ©gia de fallback**: Ter planos B e C quando o plano A falha\n",
       "- **Setup robusto**: Preparar o ambiente antes de comeÃ§ar\n",
       "\n",
       "### **ðŸŽ¯ O que vem no prÃ³ximo mÃ³dulo:**\n",
       "No prÃ³ximo mÃ³dulo, vamos mergulhar no **CrewAI** de verdade! Vamos aprender:\n",
       "- **O que Ã© CrewAI** e por que Ã© revolucionÃ¡rio\n",
       "- **Como funciona** a colaboraÃ§Ã£o entre IAs\n",
       "- **Criar nosso primeiro** sistema de agentes\n",
       "- **Entender** a diferenÃ§a entre agentes individuais e equipes\n",
       "\n",
       "---\n",
       "\n",
       "## **ðŸ’¡ Dica do Professor**\n",
       "\n",
       "> **\"Um setup bem feito Ã© metade do trabalho!\"** - Ã‰ como montar um escritÃ³rio: se vocÃª preparar tudo direito no comeÃ§o, o trabalho flui muito melhor depois.\n",
       "\n",
       "### **ðŸš€ PrÃ³ximo Passo:**\n",
       "Agora que temos tudo funcionando, vamos para o **MÃ³dulo 1: IntroduÃ§Ã£o ao CrewAI**!\n",
       "\n",
       "**ðŸŽ¯ Prepare-se para descobrir como criar um exÃ©rcito de IAs que trabalha em equipe!**"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }